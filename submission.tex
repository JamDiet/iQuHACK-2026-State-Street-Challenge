\documentclass[11pt, a4paper]{article}

% Essential Packages
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{amsmath, amssymb, amsfonts}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{float}
\usepackage{titlesec}

% Page Geometry setup
\geometry{
    left=25mm,
    right=25mm,
    top=25mm,
    bottom=25mm,
}

% Hyperlink setup
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
}

% Title Information
\title{\textbf{Quantum Risk Engineering: Accelerating VaR Analysis with IQAE and Soft-CVaR}}
\author{iQuHACK 2026 Submission}
\date{\today}

\begin{document}

\maketitle

\section{Problem Description \& Probability Model}
Value at Risk (VaR) is the standard metric for quantifying financial risk, answering the fundamental question: \textit{"What is the maximum amount I could lose with $\alpha$\% confidence?"}

For this challenge, we modeled an asset return probability distribution over a fixed time horizon using a \textbf{Gaussian distribution} with the following parameters:
\begin{itemize}
    \item Mean return ($\mu$): 15\%
    \item Standard deviation ($\sigma$): 20\%
\end{itemize}

Our goal was to estimate the VaR at high confidence levels (95\% and 99\%) and rigorously compare the computational resources required to achieve a target estimation error ($\epsilon$) using classical versus quantum methods.

\section{Classical Benchmark: Monte Carlo Simulation}
As a baseline, we implemented a classical Monte Carlo simulation to establish a performance floor. The workflow involved:
\begin{enumerate}
    \item Sampling $N$ independent returns from the defined Gaussian distribution.
    \item Sorting the samples to form an empirical Cumulative Distribution Function (CDF).
    \item Extracting the $(1-\alpha)$-quantile as the VaR estimate.
\end{enumerate}

\paragraph{Results:}
As expected, the classical error scaled according to the Central Limit Theorem:
\begin{equation}
    \epsilon \propto \frac{1}{\sqrt{N}}
\end{equation}
This scaling confirms that to improve precision by a factor of 10, the classical approach requires 100 times more samples—a prohibitive computational cost for high-frequency, high-precision risk calculations in a live trading environment.

\section{Quantum Workflow: IQAE \& Bisection Search}
Leveraging the \textbf{Classiq SDK}, we developed a quantum algorithm to estimate VaR without relying on massive sampling.

\subsection{Circuit Architecture}
\begin{itemize}
    \item \textbf{State Preparation:} We encoded the Gaussian probability distribution directly into the amplitudes of a quantum state using Classiq’s logic synthesis engine.
    \item \textbf{Threshold Oracle:} We constructed a comparator oracle that flips a target qubit if the encoded value is below a specific threshold (representing a tail event).
    \item \textbf{Estimation Routine:} Instead of simple sampling, we employed \textbf{Iterative Quantum Amplitude Estimation (IQAE)}. Unlike standard QAE, IQAE does not require Quantum Phase Estimation (QPE), allowing for reduced circuit depth while maintaining the Heisenberg scaling advantage.
\end{itemize}

\subsection{The Search Algorithm}
To find the specific VaR threshold, we wrapped the IQAE routine in a classical \textbf{Bisection Search}. The algorithm iteratively guesses a threshold $K$, estimates the cumulative probability $P(X \le K)$ using IQAE, and adjusts the search window until the probability converges to $1-\alpha$.

\section{Comparison \& Sensitivity Analysis}

\subsection{Accuracy vs. Queries (The Quantum Advantage)}
We performed a rigorous head-to-head comparison of convergence rates.
\begin{itemize}
    \item \textbf{Classical:} Exhibited the standard $\mathcal{O}(1/\epsilon^2)$ convergence.
    \item \textbf{Quantum:} Our IQAE implementation demonstrated a convergence scaling of approximately $\mathcal{O}(1/\epsilon)$.
\end{itemize}

\begin{figure}[H]
    \centering
    % Ensure the filename matches exactly what is in your folder
    \includegraphics[width=0.85\textwidth]{Graphs/estimation_error_IQAEvsmc.png}
    \caption{Log-log plot showing the estimation error $\epsilon$ decreasing significantly faster for the Quantum (IQAE) method compared to Classical Monte Carlo as the number of oracle calls increases.}
    \label{fig:error_scaling}
\end{figure}

\subsection{Sensitivity Analysis}
\begin{itemize}
    \item \textbf{Confidence Levels:} At higher confidence levels (e.g., 99\%), classical methods struggled to capture rare tail events without increasing $N$ drastically. The quantum method, leveraging amplitude amplification, identified these tail probabilities more efficiently.
    \item \textbf{Discretization (Qubit Count):} We analyzed the impact of grid resolution on accuracy. Using fewer qubits (e.g., 7) introduced discretization artifacts (step-like CDFs), while higher qubit counts (e.g., 15) smoothed the distribution, reducing modeling error at the cost of circuit depth.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{Extension-New-Algo/15_qubit_analysis.png}
    \caption{Analysis of distribution smoothness and tail event capture using 15 qubits.}
    \label{fig:15_qubit}
\end{figure}

\section{Novel Extension: The ``Soft-CVaR'' Architecture}
Beyond the standard comparison, we developed a novel variational approach for \textbf{Conditional Value at Risk (CVaR)} to address the ``discontinuity bottleneck'' in standard quantum algorithms.

By applying \textbf{Fenchel-Moreau analytic smoothing}, we replaced the sharp indicator functions typically used in risk analysis with smooth approximations. This allows us to use \textbf{Variational Quantum Signal Processing (V-QSP)} to approximate the risk function.

\begin{itemize}
    \item \textbf{Key Innovation:} This method reduces the polynomial approximation degree required from $\mathcal{O}(1/\epsilon)$ to $\mathcal{O}(\log(1/\epsilon))$.
    \item \textbf{Impact:} This theoretically allows for risk estimation with exponentially shallower circuits compared to arithmetic-heavy approaches, effectively bypassing the Gibbs phenomenon.
\end{itemize}

\section{Discussion \& Conclusion}
Our analysis demonstrates a clear separation between classical and quantum risk estimation regimes.

\begin{enumerate}
    \item \textbf{Advantage:} The quantum quadratic speedup ($\mathcal{O}(1/\epsilon)$) is validated in the Classiq simulator. This advantage is most pronounced in high-precision regimes where classical Monte Carlo hits a ``computational wall.''
    \item \textbf{Assumptions:} The advantage assumes efficient state preparation. The ``Soft-CVaR'' extension further suggests that by changing the mathematical definition of the risk function to be smooth, we can extract quantum advantage even earlier in the fault-tolerant era.
    \item \textbf{Final Verdict:} While classical Monte Carlo remains efficient for rough estimates, IQAE combined with Bisection Search offers a superior scaling pathway for the high-precision demands of regulatory capital calculation.
\end{enumerate}

\end{document}